{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "import networkx as nx\n",
    "from scipy.stats import zscore\n",
    "\n",
    "sns.set_palette(\"husl\")\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "\n",
    "os.makedirs('figures', exist_ok=True)\n",
    "os.makedirs('output', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TraderSentimentAnalyzer:\n",
    "    def __init__(self, historical_data_path, fear_greed_path):\n",
    "        self.historical_data_path = historical_data_path\n",
    "        self.fear_greed_path = fear_greed_path\n",
    "        self.historical_data = None\n",
    "        self.fear_greed_data = None\n",
    "        self.merged_data = None\n",
    "        self.trader_metrics = None\n",
    "\n",
    "    def load_and_preprocess_data(self):\n",
    "        print(\"Loading historical trader data...\")\n",
    "        if not os.path.exists(self.historical_data_path):\n",
    "            raise FileNotFoundError(f\"Historical data file not found at {self.historical_data_path}\")\n",
    "        self.historical_data = pd.read_csv(self.historical_data_path)\n",
    "        print(f\"Historical columns: {self.historical_data.columns.tolist()}\")\n",
    "      \n",
    "        if 'Timestamp IST' in self.historical_data.columns:\n",
    "            self.historical_data['Timestamp IST'] = pd.to_datetime(\n",
    "                self.historical_data['Timestamp IST'], errors='coerce', dayfirst=True)\n",
    "            self.historical_data['Date'] = self.historical_data['Timestamp IST'].dt.date\n",
    "        else:\n",
    "          \n",
    "            time_cols = [c for c in self.historical_data.columns if 'time' in c.lower()]\n",
    "            if time_cols:\n",
    "                col = time_cols[0]\n",
    "                print(f\"Parsing datetime from {col}\")\n",
    "                self.historical_data['Timestamp'] = pd.to_datetime(self.historical_data[col], errors='coerce')\n",
    "                self.historical_data['Date'] = self.historical_data['Timestamp'].dt.date\n",
    "            else:\n",
    "                raise KeyError(\"No timestamp column found in historical data.\")\n",
    "       \n",
    "        for col in ['Size USD', 'Closed PnL', 'Execution Price']:\n",
    "            if col in self.historical_data.columns:\n",
    "                self.historical_data[col] = pd.to_numeric(self.historical_data[col], errors='coerce')\n",
    "        \n",
    "        if 'Account' not in self.historical_data.columns:\n",
    "            possible = [col for col in self.historical_data.columns if col.lower() == 'account']\n",
    "            if possible:\n",
    "                self.historical_data.rename(columns={possible[0]: 'Account'}, inplace=True)\n",
    "            else:\n",
    "                raise KeyError(\"No 'Account' column found.\")\n",
    "        print(\"Loading Fear & Greed Index data...\")\n",
    "        if not os.path.exists(self.fear_greed_path):\n",
    "            raise FileNotFoundError(f\"Fear & Greed data file not found at {self.fear_greed_path}\")\n",
    "        self.fear_greed_data = pd.read_csv(self.fear_greed_path)\n",
    "        if 'date' not in self.fear_greed_data.columns:\n",
    "            raise KeyError(\"No 'date' column in Fear & Greed data.\")\n",
    "        self.fear_greed_data['date'] = pd.to_datetime(self.fear_greed_data['date'], errors='coerce')\n",
    "        self.fear_greed_data['Date'] = self.fear_greed_data['date'].dt.date\n",
    "        print(f\"Historical shape: {self.historical_data.shape}, FearGreed shape: {self.fear_greed_data.shape}\")\n",
    "\n",
    "    def merge_datasets(self):\n",
    "        print(\"Merging datasets...\")\n",
    "        fg = self.fear_greed_data\n",
    "        merge_cols = ['Date']\n",
    "        if 'value' in fg.columns:\n",
    "            merge_cols.append('value')\n",
    "        if 'classification' in fg.columns:\n",
    "            merge_cols.append('classification')\n",
    "        fg_sub = fg[merge_cols].drop_duplicates(subset=['Date'])\n",
    "        self.merged_data = pd.merge(self.historical_data, fg_sub, on='Date', how='left')\n",
    "        if 'value' in self.merged_data.columns:\n",
    "            self.merged_data.rename(columns={'value':'fear_greed_value'}, inplace=True)\n",
    "        if 'classification' in self.merged_data.columns:\n",
    "            self.merged_data.rename(columns={'classification':'sentiment'}, inplace=True)\n",
    "        # Forward fill\n",
    "        self.merged_data['fear_greed_value'] = self.merged_data['fear_greed_value'].fillna(method='ffill')\n",
    "        self.merged_data['sentiment'] = self.merged_data['sentiment'].fillna(method='ffill')\n",
    "        print(f\"Merged shape: {self.merged_data.shape}, Date range: {self.merged_data['Date'].min()} to {self.merged_data['Date'].max()}\")\n",
    "\n",
    "    def calculate_trader_metrics(self):\n",
    "        print(\"Calculating trader metrics...\")\n",
    "        rows = []\n",
    "        df = self.merged_data\n",
    "        for acct, group in df.groupby('Account'):\n",
    "            for sent, g2 in group.groupby('sentiment'):\n",
    "                total_trades = len(g2)\n",
    "                total_vol = g2['Size USD'].sum() if 'Size USD' in g2 else np.nan\n",
    "                total_pnl = g2['Closed PnL'].sum() if 'Closed PnL' in g2 else np.nan\n",
    "                avg_size = g2['Size USD'].mean() if 'Size USD' in g2 else np.nan\n",
    "                win_rate = (g2['Closed PnL']>0).mean() if 'Closed PnL' in g2 else np.nan\n",
    "                avg_fg = g2['fear_greed_value'].mean() if 'fear_greed_value' in g2 else np.nan\n",
    "                rows.append({'Account':acct,'Sentiment':sent,'Total_Trades':total_trades,\n",
    "                             'Total_Volume_USD':total_vol,'Total_PnL':total_pnl,\n",
    "                             'Avg_Trade_Size':avg_size,'Win_Rate':win_rate,'Avg_Fear_Greed_Value':avg_fg})\n",
    "        self.trader_metrics = pd.DataFrame(rows)\n",
    "        self.trader_metrics.to_csv('output/trader_performance_metrics.csv', index=False)\n",
    "        print(f\"Trader metrics saved: {self.trader_metrics.shape[0]} rows.\")\n",
    "\n",
    "    def analyze_sentiment_patterns(self):\n",
    "        print(\"Aggregated sentiment patterns...\")\n",
    "        df = self.merged_data\n",
    "        agg = df.groupby('sentiment').agg({\n",
    "            'Size USD':['count','sum','mean','std'],\n",
    "            'Closed PnL':['sum','mean','std'],\n",
    "            'Execution Price':['mean','std'],\n",
    "            'fear_greed_value':'mean'}).round(4)\n",
    "        agg.columns = ['_'.join(col) for col in agg.columns]\n",
    "        agg.to_csv('output/sentiment_analysis_summary.csv')\n",
    "        return agg\n",
    "\n",
    "    def create_visualizations(self):\n",
    "        print(\"Creating visualizations...\")\n",
    "        df = self.merged_data.copy()\n",
    "        # Ensure Timestamp\n",
    "        if 'Timestamp IST' in df.columns:\n",
    "            df['Timestamp'] = pd.to_datetime(df['Timestamp IST'], errors='coerce')\n",
    "        else:\n",
    "            time_cols = [c for c in df.columns if 'time' in c.lower()]\n",
    "            if time_cols:\n",
    "                df['Timestamp'] = pd.to_datetime(df[time_cols[0]], errors='coerce')\n",
    "        df['Hour'] = df['Timestamp'].dt.hour\n",
    "        # 1. Volume by sentiment\n",
    "        plt.figure();\n",
    "        vol = df.groupby('sentiment')['Size USD'].sum().sort_values(ascending=False)\n",
    "        bars=plt.bar(vol.index,vol.values); plt.title('Total Trading Volume by Sentiment'); plt.xticks(rotation=45)\n",
    "        for b in bars: plt.text(b.get_x()+b.get_width()/2,b.get_height(),f'${b.get_height():,.0f}',ha='center',va='bottom')\n",
    "        plt.tight_layout(); plt.savefig('figures/volume_by_sentiment.png'); plt.close()\n",
    "        # 2. Avg PnL by sentiment\n",
    "        plt.figure();\n",
    "        pnl= df.groupby('sentiment')['Closed PnL'].mean(); colors=['green' if x>=0 else 'red' for x in pnl.values]\n",
    "        bars=plt.bar(pnl.index,pnl.values,color=colors,alpha=0.7); plt.title('Average PnL by Sentiment'); plt.axhline(0,linestyle='--',alpha=0.5); plt.xticks(rotation=45)\n",
    "        for b in bars: h=b.get_height(); va='bottom' if h>=0 else 'top'; plt.text(b.get_x()+b.get_width()/2,h,f'{h:.2f}',ha='center',va=va)\n",
    "        plt.tight_layout(); plt.savefig('figures/avg_pnl_by_sentiment.png'); plt.close()\n",
    "        # 3. Trade distribution pie\n",
    "        plt.figure(); counts=df['sentiment'].value_counts(); plt.pie(counts.values,labels=counts.index,autopct='%1.1f%%',startangle=90); plt.title('Distribution of Trades by Sentiment'); plt.tight_layout(); plt.savefig('figures/trade_distribution_pie.png'); plt.close()\n",
    "        # 4. Fear & Greed over time\n",
    "        plt.figure(); daily=df.groupby('Date')['fear_greed_value'].first().reset_index(); daily['Date']=pd.to_datetime(daily['Date']); daily=daily.sort_values('Date')\n",
    "        plt.plot(daily['Date'],daily['fear_greed_value']); plt.fill_between(daily['Date'],daily['fear_greed_value'],alpha=0.3); plt.title('Fear & Greed Index Over Time'); plt.xticks(rotation=45); plt.axhline(25,color='red',linestyle='--',alpha=0.5); plt.axhline(75,color='green',linestyle='--',alpha=0.5); plt.tight_layout(); plt.savefig('figures/fear_greed_over_time.png'); plt.close()\n",
    "        # 5. Heatmap hour vs sentiment\n",
    "        heat = df.groupby(['Hour','sentiment']).size().unstack(fill_value=0)\n",
    "        if not heat.empty:\n",
    "            plt.figure(); sns.heatmap(heat.T,annot=True,fmt='d',cbar_kws={'label':'Number of Trades'}); plt.title('Trading Activity Heatmap'); plt.xlabel('Hour'); plt.ylabel('Sentiment'); plt.tight_layout(); plt.savefig('figures/heatmap_hour_sentiment.png'); plt.close()\n",
    "        # 6. Cumulative PnL by sentiment\n",
    "        plt.figure();\n",
    "        for sent in df['sentiment'].dropna().unique():\n",
    "            sub=df[df['sentiment']==sent].sort_values('Timestamp'); sub['Cumulative_PnL']=sub['Closed PnL'].cumsum(); plt.plot(sub['Timestamp'],sub['Cumulative_PnL'],label=sent)\n",
    "        plt.title('Cumulative PnL by Sentiment'); plt.legend(); plt.xticks(rotation=45); plt.tight_layout(); plt.savefig('figures/cumulative_pnl.png'); plt.close()\n",
    "        # 7. Size distribution\n",
    "        plt.figure();\n",
    "        for sent in df['sentiment'].dropna().unique(): plt.hist(df[df['sentiment']==sent]['Size USD'].dropna(),bins=50,alpha=0.5,density=True,label=sent)\n",
    "        plt.yscale('log'); plt.title('Trade Size Distribution by Sentiment'); plt.legend(); plt.tight_layout(); plt.savefig('figures/size_distribution.png'); plt.close()\n",
    "        # 8. Win rate\n",
    "        plt.figure();\n",
    "        labels=[]; rates=[]\n",
    "        for sent in df['sentiment'].dropna().unique(): sub=df[df['sentiment']==sent]; total=len(sub); wins=(sub['Closed PnL']>0).sum(); rate=(wins/total*100 if total>0 else 0); labels.append(sent); rates.append(rate)\n",
    "        bars=plt.bar(labels,rates); plt.title('Win Rate by Sentiment'); plt.ylabel('Win Rate (%)'); plt.xticks(rotation=45)\n",
    "        for b in bars: plt.text(b.get_x()+b.get_width()/2,b.get_height(),f'{b.get_height():.1f}%',ha='center',va='bottom')\n",
    "        plt.tight_layout(); plt.savefig('figures/win_rate.png'); plt.close()\n",
    "        print(\"Visualizations saved in figures/\")\n",
    "\n",
    "    def generate_insights(self):\n",
    "        print(\"Generating insights...\")\n",
    "        df=self.merged_data\n",
    "        # Distribution\n",
    "        total=len(df)\n",
    "        dist=df['sentiment'].value_counts()\n",
    "        insights=[]\n",
    "        insights.append(\"Market Sentiment Distribution:\")\n",
    "        for sent,count in dist.items(): insights.append(f\"  {sent}: {count} trades ({count/total*100:.1f}%)\")\n",
    "        # Profitability\n",
    "        stats=df.groupby('sentiment').agg({'Closed PnL':['sum','mean'],'Size USD':'count'}).round(4)\n",
    "        stats.columns=['_'.join(col) for col in stats.columns]\n",
    "        insights.append(\"\\nProfitability by Sentiment:\")\n",
    "        for sent,row in stats.iterrows(): insights.append(f\"  {sent}: Total PnL=${row['Closed PnL_sum']:.2f}, Avg PnL=${row['Closed PnL_mean']:.4f}, Trades={int(row['Size USD_count'])}\")\n",
    "        # Volume\n",
    "        vol=df.groupby('sentiment')['Size USD'].agg(['sum','mean']).round(2)\n",
    "        insights.append(\"\\nVolume Analysis:\")\n",
    "        for sent,row in vol.iterrows(): insights.append(f\"  {sent}: Total Volume=${row['sum']:.2f}, Avg Size=${row['mean']:.2f}\")\n",
    "        # Correlations\n",
    "        corr_pnl=df['fear_greed_value'].corr(df['Closed PnL'])\n",
    "        corr_size=df['fear_greed_value'].corr(df['Size USD'])\n",
    "        insights.append(f\"\\nCorrelation Fear & Greed vs PnL: {corr_pnl:.4f}\")\n",
    "        insights.append(f\"Correlation Fear & Greed vs Size: {corr_size:.4f}\")\n",
    "        # Recommendations\n",
    "        mean_pnl= df.groupby('sentiment')['Closed PnL'].mean()\n",
    "        most_prof= mean_pnl.idxmax() if not mean_pnl.empty else None\n",
    "        insights.append(f\"\\nMost Profitable Sentiment: {most_prof}\")\n",
    "        sum_vol= df.groupby('sentiment')['Size USD'].sum()\n",
    "        high_vol= sum_vol.idxmax() if not sum_vol.empty else None\n",
    "        insights.append(f\"Highest Volume Sentiment: {high_vol}\")\n",
    "        std_pnl=df.groupby('sentiment')['Closed PnL'].std()\n",
    "        low_risk= std_pnl.idxmin() if not std_pnl.empty else None\n",
    "        insights.append(f\"Lowest Risk Sentiment: {low_risk}\")\n",
    "        insights.append(\"\\nActionable Insights:\")\n",
    "        insights.append(\"  - Consider contrarian trades around extremes\")\n",
    "        insights.append(\"  - Exploit volume opportunities during fear\")\n",
    "        insights.append(\"  - Adjust risk management by sentiment\")\n",
    "        insights.append(\"  - Monitor sentiment transitions for timing\")\n",
    "        # Risk-adjusted\n",
    "        insights.append(\"\\nRisk-Adjusted Returns:\")\n",
    "        for sent in mean_pnl.index:\n",
    "            m=mean_pnl[sent]; s=std_pnl[sent]\n",
    "            if s and s>0: insights.append(f\"  {sent}: {m/s:.4f}\")\n",
    "        # Extreme\n",
    "        ext_fear=df[df['fear_greed_value']<=25]\n",
    "        ext_greed=df[df['fear_greed_value']>=75]\n",
    "        if not ext_fear.empty: insights.append(f\"\\nExtreme Fear (<=25) Avg PnL: ${ext_fear['Closed PnL'].mean():.4f}\")\n",
    "        if not ext_greed.empty: insights.append(f\"Extreme Greed (>=75) Avg PnL: ${ext_greed['Closed PnL'].mean():.4f}\")\n",
    "        # Save insights\n",
    "        with open('output/insights.txt','w') as f:\n",
    "            f.write(\"\\n\".join(insights))\n",
    "        print(\"Insights saved to output/insights.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedTraderAnalysis:\n",
    "    def __init__(self, merged_path):\n",
    "        if not os.path.exists(merged_path): raise FileNotFoundError\n",
    "        self.df=pd.read_csv(merged_path, parse_dates=['Timestamp IST','Date'], dayfirst=True)\n",
    "        if 'Timestamp IST' in self.df.columns:\n",
    "            self.df['Timestamp']=pd.to_datetime(self.df['Timestamp IST'],errors='coerce')\n",
    "        else:\n",
    "            time_cols=[c for c in self.df.columns if 'time' in c.lower()]\n",
    "            if time_cols: self.df['Timestamp']=pd.to_datetime(self.df[time_cols[0]],errors='coerce')\n",
    "        self.df['Date']=pd.to_datetime(self.df['Date'],errors='coerce')\n",
    "\n",
    "    def predictive_model(self):\n",
    "        print(\"Predictive model...\")\n",
    "        df=self.df.copy(); df['target']=(df['Closed PnL']>0).astype(int); df['Hour']=df['Timestamp'].dt.hour\n",
    "        features=['Size USD','Execution Price','fear_greed_value','Hour']\n",
    "        dfm=df[features+['target']].dropna()\n",
    "        X=dfm[features]; y=dfm['target']\n",
    "        X_train,X_test,y_train,y_test=train_test_split(X,y,stratify=y,random_state=42)\n",
    "        model=RandomForestClassifier(n_estimators=100,random_state=42)\n",
    "        model.fit(X_train,y_train)\n",
    "        y_pred=model.predict(X_test)\n",
    "        report=classification_report(y_test,y_pred); cm=confusion_matrix(y_test,y_pred)\n",
    "        with open('output/predictive_report.txt','w') as f: f.write(report + '\\nConfusion Matrix:\\n' + str(cm))\n",
    "        print(\"Predictive report saved.\")\n",
    "\n",
    "    def time_series_forecasting(self):\n",
    "        print(\"Time-series forecasting...\")\n",
    "        df=self.df.copy(); df_daily=df.groupby('Date').agg({'Closed PnL':'mean','fear_greed_value':'mean'}).dropna()\n",
    "        try:\n",
    "            model=SARIMAX(df_daily['Closed PnL'], exog=df_daily[['fear_greed_value']], order=(1,1,1))\n",
    "            res=model.fit(disp=False)\n",
    "            last_exog=df_daily[['fear_greed_value']].iloc[-10:]\n",
    "            forecast=res.forecast(steps=10, exog=last_exog)\n",
    "            forecast.to_csv('output/forecast_next10.csv')\n",
    "            print(\"Forecast saved to output/forecast_next10.csv\")\n",
    "        except Exception as e:\n",
    "            print(f\"Forecast error: {e}\")\n",
    "\n",
    "    def detect_anomalies(self):\n",
    "        print(\"Anomaly detection...\")\n",
    "        df=self.df; feats=['Size USD','Closed PnL','Execution Price']\n",
    "        df2=df[feats].dropna()\n",
    "        iso=IsolationForest(contamination=0.02,random_state=42)\n",
    "        df2['anomaly']=iso.fit_predict(df2)\n",
    "        anomalies=df2[df2['anomaly']==-1]\n",
    "        anomalies.to_csv('output/anomalous_trades.csv',index=False)\n",
    "        print(f\"Anomalies saved: {len(anomalies)} rows.\")\n",
    "\n",
    "    def sentiment_transition_analysis(self):\n",
    "        print(\"Sentiment transitions...\")\n",
    "        df=self.df.sort_values('Timestamp'); df['prev_sent']=df['sentiment'].shift(1); df['change']=df['sentiment']!=df['prev_sent']\n",
    "        trans=df[df['change']]\n",
    "        res=trans.groupby(['prev_sent','sentiment'])['Closed PnL'].mean().reset_index()\n",
    "        res.columns=['From','To','Avg_PnL']; res.to_csv('output/sentiment_transitions.csv',index=False)\n",
    "        print(\"Sentiment transitions saved.\")\n",
    "\n",
    "    def plot_volume_and_pnl_over_time(self):\n",
    "        print(\"Plot volume and avg PnL...\")\n",
    "        df=self.df; df_daily=df.groupby('Date').agg({'Size USD':'sum','Closed PnL':'mean'})\n",
    "        plt.figure(); df_daily['Size USD'].plot(title='Total Volume Over Time'); plt.tight_layout(); plt.savefig('figures/volume_time_series.png'); plt.close()\n",
    "        plt.figure(); df_daily['Closed PnL'].plot(title='Average PnL Over Time'); plt.tight_layout(); plt.savefig('figures/avg_pnl_time_series.png'); plt.close()\n",
    "        print(\"Time series plots saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ExtendedTraderAnalysis:\n",
    "    def __init__(self, merged_path):\n",
    "        if not os.path.exists(merged_path): raise FileNotFoundError\n",
    "        self.df=pd.read_csv(merged_path,parse_dates=['Timestamp IST','Date'],dayfirst=True)\n",
    "        if 'Timestamp IST' in self.df.columns: self.df['Timestamp']=pd.to_datetime(self.df['Timestamp IST'],errors='coerce')\n",
    "        else:\n",
    "            tcols=[c for c in self.df.columns if 'time' in c.lower()]\n",
    "            if tcols: self.df['Timestamp']=pd.to_datetime(self.df[tcols[0]],errors='coerce')\n",
    "        self.df['Date']=pd.to_datetime(self.df['Date'],errors='coerce')\n",
    "        # daily\n",
    "        self.daily=self.df.groupby('Date').agg(avg_pnl=('Closed PnL','mean'),avg_fg=('fear_greed_value','mean')).dropna().sort_index()\n",
    "        self.trader_metrics = pd.read_csv('output/trader_performance_metrics.csv') if os.path.exists('output/trader_performance_metrics.csv') else None\n",
    "\n",
    "    def cluster_traders(self, n_clusters=4):\n",
    "        print(\"Clustering traders...\")\n",
    "        if self.trader_metrics is None:\n",
    "            print(\"Trader metrics missing.\"); return\n",
    "        feat=['Win_Rate','Total_PnL','Avg_Trade_Size'] if 'Win_Rate' in self.trader_metrics.columns else []\n",
    "       \n",
    "        # Here use columns: Win_Rate, Avg_Trade_Size, Total_PnL, perhaps Avg_Fear_Greed_Value\n",
    "        cols=[c for c in ['Win_Rate','Avg_Trade_Size','Total_PnL','Avg_Fear_Greed_Value'] if c in self.trader_metrics.columns]\n",
    "        dfm=self.trader_metrics.dropna(subset=cols)\n",
    "        X=StandardScaler().fit_transform(dfm[cols])\n",
    "        labels=KMeans(n_clusters=n_clusters,random_state=42).fit_predict(X)\n",
    "        dfm['Cluster']=labels; dfm.to_csv('output/trader_clusters.csv',index=False)\n",
    "        print(f\"Clusters saved, sample:\\n{dfm.head()}\" )\n",
    "\n",
    "    def time_lag_correlation(self, max_lag=10):\n",
    "        print(\"Time-lag correlation...\")\n",
    "        series_pnl=self.daily['avg_pnl']; series_fg=self.daily['avg_fg']\n",
    "        results=[]\n",
    "        for lag in range(-max_lag,max_lag+1):\n",
    "            if lag<0: corr=series_fg.shift(-lag).corr(series_pnl)\n",
    "            else: corr=series_fg.shift(lag).corr(series_pnl)\n",
    "            results.append({'lag':lag,'corr':corr})\n",
    "        df_lag=pd.DataFrame(results); df_lag.to_csv('output/time_lag_correlation.csv',index=False)\n",
    "        plt.figure(); plt.bar(df_lag['lag'],df_lag['corr']); plt.title('Cross-correlation'); plt.xlabel('Lag'); plt.ylabel('Correlation'); plt.tight_layout(); plt.savefig('figures/time_lag_correlation.png'); plt.close()\n",
    "        print(\"Time-lag correlation saved.\")\n",
    "\n",
    "    def granger_causality(self, maxlag=5):\n",
    "        print(\"Granger causality tests...\")\n",
    "        data=self.daily[['avg_pnl','avg_fg']].dropna()\n",
    "        try:\n",
    "            g1=grangercausalitytests(data[['avg_pnl','avg_fg']],maxlag=maxlag,verbose=False)\n",
    "            p1={lag:g1[lag][0]['ssr_ftest'][1] for lag in g1}\n",
    "            with open('output/granger_sentiment_to_pnl.txt','w') as f: f.write(str(p1))\n",
    "            print(f\"Sentiment->PnL p-values: {p1}\")\n",
    "        except Exception as e: print(f\"Error: {e}\")\n",
    "        try:\n",
    "            g2=grangercausalitytests(data[['avg_fg','avg_pnl']],maxlag=maxlag,verbose=False)\n",
    "            p2={lag:g2[lag][0]['ssr_ftest'][1] for lag in g2}\n",
    "            with open('output/granger_pnl_to_sentiment.txt','w') as f: f.write(str(p2))\n",
    "            print(f\"PnL->Sentiment p-values: {p2}\")\n",
    "        except Exception as e: print(f\"Error: {e}\")\n",
    "\n",
    "    def event_study_extreme(self, window=5):\n",
    "        print(\"Event study around extremes...\")\n",
    "        df=self.daily\n",
    "        ext_fear=df[df['avg_fg']<=25].index\n",
    "        ext_greed=df[df['avg_fg']>=75].index\n",
    "        def comp(dates):\n",
    "            rec=[]\n",
    "            for d in dates:\n",
    "                for off in range(-window,window+1):\n",
    "                    day=d+timedelta(days=off)\n",
    "                    if day in df.index: rec.append({'event_date':d,'offset':off,'avg_pnl':df.at[day,'avg_pnl']})\n",
    "            return pd.DataFrame(rec)\n",
    "        df_f=comp(ext_fear); df_g=comp(ext_greed)\n",
    "        agg_f=df_f.groupby('offset')['avg_pnl'].mean().reset_index(); agg_g=df_g.groupby('offset')['avg_pnl'].mean().reset_index()\n",
    "        plt.figure(); plt.plot(agg_f['offset'],agg_f['avg_pnl'],label='Fear'); plt.plot(agg_g['offset'],agg_g['avg_pnl'],label='Greed'); plt.axvline(0,linestyle='--'); plt.title('Event Study'); plt.xlabel('Days relative'); plt.ylabel('Avg PnL'); plt.legend(); plt.tight_layout(); plt.savefig('figures/event_study_extreme.png'); plt.close()\n",
    "        agg_f.to_csv('output/event_study_fear.csv',index=False); agg_g.to_csv('output/event_study_greed.csv',index=False)\n",
    "        print(\"Event study results saved.\")\n",
    "\n",
    "    def pca_tsne_trader_metrics(self):\n",
    "        print(\"PCA/t-SNE on trader metrics...\")\n",
    "        if not os.path.exists('output/trader_performance_metrics.csv'): print(\"Metrics missing\"); return\n",
    "        dfm=pd.read_csv('output/trader_performance_metrics.csv')\n",
    "        cols=['Win_Rate','Avg_Trade_Size','Total_PnL','Avg_Fear_Greed_Value']\n",
    "        cols=[c for c in cols if c in dfm.columns]\n",
    "        dfm=dfm.dropna(subset=cols)\n",
    "        X=StandardScaler().fit_transform(dfm[cols])\n",
    "        pca=PCA(n_components=2,random_state=42).fit_transform(X)\n",
    "        dfm['PC1'],dfm['PC2']=pca[:,0],pca[:,1]\n",
    "        plt.figure(); sns.scatterplot(x='PC1',y='PC2',data=dfm); plt.title('PCA'); plt.tight_layout(); plt.savefig('figures/pca_trader_metrics.png'); plt.close()\n",
    "        tsne=TSNE(n_components=2,random_state=42,perplexity=30).fit_transform(X)\n",
    "        dfm['TSNE1'],dfm['TSNE2']=tsne[:,0],tsne[:,1]\n",
    "        plt.figure(); sns.scatterplot(x='TSNE1',y='TSNE2',data=dfm); plt.title('t-SNE'); plt.tight_layout(); plt.savefig('figures/tsne_trader_metrics.png'); plt.close()\n",
    "        dfm.to_csv('output/trader_metrics_vis.csv',index=False)\n",
    "        print(\"PCA/t-SNE visualizations saved.\")\n",
    "\n",
    "    def correlation_network(self, min_corr=0.3):\n",
    "        print(\"Building correlation network...\")\n",
    "        pivot=self.df.pivot_table(index='Date',columns='Account',values='Closed PnL',aggfunc='mean')\n",
    "        corr=pivot.corr().fillna(0)\n",
    "        G=nx.Graph(); accounts=corr.columns.tolist(); G.add_nodes_from(accounts)\n",
    "        for i in range(len(accounts)):\n",
    "            for j in range(i+1,len(accounts)):\n",
    "                val=corr.iat[i,j]\n",
    "                if abs(val)>=min_corr: G.add_edge(accounts[i],accounts[j],weight=val)\n",
    "        plt.figure(figsize=(8,8)); pos=nx.spring_layout(G,seed=42); weights=[abs(d['weight']) for (_,_,d) in G.edges(data=True)]; nx.draw_networkx_nodes(G,pos,node_size=20); nx.draw_networkx_edges(G,pos,width=[w*2 for w in weights],alpha=0.5); plt.title(f'Correlation Network |corr|>={min_corr}'); plt.axis('off'); plt.tight_layout(); plt.savefig('figures/trader_network.png'); plt.close()\n",
    "        nx.write_gexf(G,'output/trader_correlation_network.gexf')\n",
    "        print(f\"Network saved: nodes={G.number_of_nodes()}, edges={G.number_of_edges()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_report():\n",
    "    print(\"Generating report.md...\")\n",
    "    lines=[]\n",
    "    lines.append(\"# Trader Behavior & Market Sentiment Analysis Report\")\n",
    "    lines.append(\"\\n## 1. Introduction\")\n",
    "    lines.append(\"This report explores relationships between trader performance and Bitcoin market sentiment (Fear & Greed index).\")\n",
    "    lines.append(\"\\n## 2. Data\")\n",
    "    lines.append(\"- Historical trader data: columns include Account, Timestamp IST, Size USD, Closed PnL, Execution Price, etc.\")\n",
    "    lines.append(\"- Fear & Greed index: date, value, classification (e.g., Fear, Greed).\")\n",
    "    lines.append(\"\\n## 3. Preprocessing & Merging\")\n",
    "    lines.append(\"Datasets were loaded, timestamps parsed, numeric columns converted, then merged on date with forward-filled missing sentiment/index.\")\n",
    "    # Summary of merged data\n",
    "    try:\n",
    "        df=pd.read_csv('output/merged_trader_sentiment_data.csv')\n",
    "        lines.append(f\"- Merged dataset shape: {df.shape}\")\n",
    "    except:\n",
    "        lines.append(\"- Merged dataset summary not found.\")\n",
    "    lines.append(\"\\n## 4. Trader Metrics\")\n",
    "    try:\n",
    "        tm=pd.read_csv('output/trader_performance_metrics.csv')\n",
    "        lines.append(f\"- Trader metrics: {tm.shape[0]} account-sentiment entries.\")\n",
    "        lines.append(tm.head().to_markdown(index=False))\n",
    "    except:\n",
    "        lines.append(\"- Trader metrics not available.\")\n",
    "    lines.append(\"\\n## 5. Aggregated Sentiment Patterns\")\n",
    "    try:\n",
    "        sa=pd.read_csv('output/sentiment_analysis_summary.csv', index_col=0)\n",
    "        lines.append(sa.reset_index().to_markdown(index=False))\n",
    "    except:\n",
    "        lines.append(\"- Sentiment summary not available.\")\n",
    "    lines.append(\"\\n## 6. Visualizations\")\n",
    "    figs=['volume_by_sentiment.png','avg_pnl_by_sentiment.png','trade_distribution_pie.png',\n",
    "          'fear_greed_over_time.png','heatmap_hour_sentiment.png','cumulative_pnl.png',\n",
    "          'size_distribution.png','win_rate.png','volume_time_series.png','avg_pnl_time_series.png',\n",
    "          'time_lag_correlation.png','event_study_extreme.png','pca_trader_metrics.png','tsne_trader_metrics.png','trader_network.png']\n",
    "    for f in figs:\n",
    "        path=os.path.join('figures',f)\n",
    "        if os.path.exists(path): lines.append(f\"![{f}]({path})\")\n",
    "    lines.append(\"\\n## 7. Insights\")\n",
    "    try:\n",
    "        ins=open('output/insights.txt').read().splitlines()\n",
    "        lines.append(\"```\")\n",
    "        lines.extend(ins)\n",
    "        lines.append(\"```\")\n",
    "    except:\n",
    "        lines.append(\"- Insights not available.\")\n",
    "    lines.append(\"\\n## 8. Advanced Analyses\")\n",
    "    adv_files=['output/predictive_report.txt','output/forecast_next10.csv','output/anomalous_trades.csv','output/sentiment_transitions.csv','output/time_lag_correlation.csv','output/event_study_fear.csv','output/event_study_greed.csv']\n",
    "    for af in adv_files:\n",
    "        if os.path.exists(af):\n",
    "            lines.append(f\"### {af}\\n```\")\n",
    "            with open(af) as f: lines.append(f.read())\n",
    "            lines.append(\"```\")\n",
    "    lines.append(\"\\n## 9. Methods & Models\")\n",
    "    lines.append(\"- Classification: RandomForest to predict profitable trades using Size USD, Execution Price, FearGreed value, Hour.\")\n",
    "    lines.append(\"- Forecasting: SARIMAX on avg daily PnL with sentiment as exogenous.\")\n",
    "    lines.append(\"- Anomaly Detection: IsolationForest on Size USD, PnL, Execution Price.\")\n",
    "    lines.append(\"- Clustering: KMeans on trader performance features.\")\n",
    "    lines.append(\"- Time-lag correlation and Granger causality between sentiment and avg PnL.\")\n",
    "    lines.append(\"- Event study around extreme sentiment days.\")\n",
    "    lines.append(\"- PCA and t-SNE for visualization of trader clusters.\")\n",
    "    lines.append(\"- Correlation network among traders based on daily PnL correlations.\")\n",
    "    lines.append(\"\\n## 10. Conclusions & Recommendations\")\n",
    "    lines.append(\"- Summarize key findings: which sentiments yield higher avg returns, risk profiles, predictive power of sentiment, timing strategies around extremes, clustering insights.\")\n",
    "    lines.append(\"- Recommendations: contrarian strategies, risk adjustments, monitoring sentiment transitions, anomaly monitoring.\")\n",
    "    with open('report.md','w') as f:\n",
    "        f.write(\"\\n\\n\".join(lines))\n",
    "    print(\"report.md generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading historical trader data...\n",
      "Historical columns: ['Account', 'Coin', 'Execution Price', 'Size Tokens', 'Size USD', 'Side', 'Timestamp IST', 'Start Position', 'Direction', 'Closed PnL', 'Transaction Hash', 'Order ID', 'Crossed', 'Fee', 'Trade ID', 'Timestamp']\n",
      "Loading Fear & Greed Index data...\n",
      "Historical shape: (211224, 17), FearGreed shape: (2644, 5)\n",
      "Merging datasets...\n",
      "Merged shape: (211224, 19), Date range: 2023-05-01 to 2025-05-01\n",
      "Calculating trader metrics...\n",
      "Trader metrics saved: 156 rows.\n",
      "Aggregated sentiment patterns...\n",
      "Creating visualizations...\n",
      "Visualizations saved in figures/\n",
      "Generating insights...\n",
      "Insights saved to output/insights.txt\n",
      "Predictive model...\n",
      "Predictive report saved.\n",
      "Time-series forecasting...\n",
      "Forecast saved to output/forecast_next10.csv\n",
      "Anomaly detection...\n",
      "Anomalies saved: 4225 rows.\n",
      "Sentiment transitions...\n",
      "Sentiment transitions saved.\n",
      "Plot volume and avg PnL...\n",
      "Time series plots saved.\n",
      "Clustering traders...\n",
      "Clusters saved, sample:\n",
      "                                      Account      Sentiment  Total_Trades  \\\n",
      "0  0x083384f897ee0f19899168e3b1bec365f52a9012   Extreme Fear           100   \n",
      "1  0x083384f897ee0f19899168e3b1bec365f52a9012  Extreme Greed           945   \n",
      "2  0x083384f897ee0f19899168e3b1bec365f52a9012           Fear          1778   \n",
      "3  0x083384f897ee0f19899168e3b1bec365f52a9012          Greed           574   \n",
      "4  0x083384f897ee0f19899168e3b1bec365f52a9012        Neutral           421   \n",
      "\n",
      "   Total_Volume_USD     Total_PnL  Avg_Trade_Size  Win_Rate  \\\n",
      "0        1507100.86  1.247692e+05    15071.008600  0.370000   \n",
      "1       11415855.67 -4.028234e+04    12080.270550  0.066667   \n",
      "2       30262439.89  1.113374e+06    17020.494876  0.526434   \n",
      "3        8686990.84  2.767193e+05    15134.130383  0.160279   \n",
      "4        9824876.71  1.256501e+05    23336.999311  0.581948   \n",
      "\n",
      "   Avg_Fear_Greed_Value  Cluster  \n",
      "0             17.800000        1  \n",
      "1             78.391534        3  \n",
      "2             37.649606        2  \n",
      "3             71.790941        1  \n",
      "4             50.413302        1  \n",
      "Time-lag correlation...\n",
      "Time-lag correlation saved.\n",
      "Granger causality tests...\n",
      "Sentiment->PnL p-values: {np.int64(1): np.float64(0.49645737873481566), np.int64(2): np.float64(0.7831322667834546), np.int64(3): np.float64(0.8605865784421796), np.int64(4): np.float64(0.939783482162487), np.int64(5): np.float64(0.9767728754659424)}\n",
      "PnL->Sentiment p-values: {np.int64(1): np.float64(0.325519409662528), np.int64(2): np.float64(0.46853482232993393), np.int64(3): np.float64(0.679768777444939), np.int64(4): np.float64(0.5652120855725223), np.int64(5): np.float64(0.5830423063633883)}\n",
      "Event study around extremes...\n",
      "Event study results saved.\n",
      "PCA/t-SNE on trader metrics...\n",
      "PCA/t-SNE visualizations saved.\n",
      "Building correlation network...\n",
      "Network saved: nodes=32, edges=147\n",
      "Generating report.md...\n",
      "report.md generated.\n",
      "Full analysis completed. See report.md, figures/, and output/ for results.\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    \n",
    "    hist_path='data/historical_data.csv'\n",
    "    fg_path='data/fear_greed_index.csv'\n",
    "    merged_path='output/merged_trader_sentiment_data.csv'\n",
    " \n",
    "    analyzer=TraderSentimentAnalyzer(hist_path,fg_path)\n",
    "    analyzer.load_and_preprocess_data()\n",
    "    analyzer.merge_datasets()\n",
    "   \n",
    "    analyzer.merged_data.to_csv(merged_path,index=False)\n",
    "    analyzer.calculate_trader_metrics()\n",
    "    analyzer.analyze_sentiment_patterns()\n",
    "    analyzer.create_visualizations()\n",
    "    analyzer.generate_insights()\n",
    "    \n",
    "    adv=AdvancedTraderAnalysis(merged_path)\n",
    "    adv.predictive_model()\n",
    "    adv.time_series_forecasting()\n",
    "    adv.detect_anomalies()\n",
    "    adv.sentiment_transition_analysis()\n",
    "    adv.plot_volume_and_pnl_over_time()\n",
    "    ext=ExtendedTraderAnalysis(merged_path)\n",
    "    ext.cluster_traders(n_clusters=4)\n",
    "    ext.time_lag_correlation(max_lag=10)\n",
    "    ext.granger_causality(maxlag=5)\n",
    "    ext.event_study_extreme(window=5)\n",
    "    ext.pca_tsne_trader_metrics()\n",
    "    ext.correlation_network(min_corr=0.3)\n",
    "    \n",
    "    generate_report()\n",
    "    print(\"Full analysis completed. See report.md, figures/, and output/ for results.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
